# Story 1.4: URL Discovery and Sitemap Parsing

## Status
Draft

## Story
**As a** user,
**I want** to input a website URL and automatically discover its structure,
**so that** I can understand the scope of analysis and select specific pages to examine.

## Acceptance Criteria
1. MCP tool `discover_website` accepts URL input and returns organized site structure
2. Automatic sitemap.xml parsing and URL extraction with error handling for missing sitemaps
3. Robots.txt analysis to identify additional URLs and crawling restrictions
4. Manual crawling fallback with configurable depth limits for sites without sitemaps
5. URL categorization and filtering (pages vs. assets, internal vs. external links)
6. Generated URL inventory saved to project folder with metadata (titles, descriptions, estimated complexity)
7. Progress reporting during discovery process for large websites

## Tasks / Subtasks
- [ ] Implement `discover_website` tool orchestrating discovery pipeline (AC: 1)
  - [ ] Validate and sanitize input URL using architecture security rules (AC: 1)
- [ ] Add sitemap parsing module (AC: 2)
  - [ ] Fetch and parse sitemap.xml with robust error handling and logging (AC: 2)
- [ ] Integrate robots.txt analysis (AC: 3)
  - [ ] Respect crawl directives and augment URL list with allowed paths (AC: 3)
- [ ] Build manual crawling fallback (AC: 4)
  - [ ] Implement bounded BFS/DFS with configurable depth from configuration defaults (AC: 4)
- [ ] Categorize and filter discovered URLs (AC: 5)
  - [ ] Distinguish page types, dedupe, and annotate internal/external classification (AC: 5)
- [ ] Persist URL inventory to project storage (AC: 6)
  - [ ] Save structured JSON/YAML with metadata including title, description, complexity heuristics (AC: 6)
- [ ] Emit progress updates during discovery (AC: 7)
  - [ ] Stream status via MCP resource or tool notifications for long-running operations (AC: 7)

## Dev Notes
- Reuse the storage layout from `docs/prd.md#story-15-project-organization-and-file-structure` and the Project model in `docs/architecture.md#project` to keep discovery artifacts compatible.
- Utilize AsyncIO to parallelize fetching while honoring the rate-limiting guidance in `docs/architecture.md#performance--scalability`.
- Generate titles/descriptions from meta tags or heuristics now, noting that deeper enrichment arrives with Epic 3 (`docs/prd.md#epic-3-llm-integration--two-step-analysis-pipeline`).
- Maintain structured logging consistent with `docs/architecture.md#architectural-and-design-patterns` for troubleshooting.
- Enforce robots.txt compliance and avoid destructive actions per the security practices in `docs/architecture.md#security`.

### Testing
- Unit tests for sitemap/robots parsers using fixture HTML files in `tests/fixtures/discovery/`.
- Integration test executing `discover_website` against mocked HTTP responses via pytest-httpx.
- Include performance test ensuring depth limits enforce expected bounds to support NFR processing times.

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-02-14 | 0.1 | Initial draft | John (PM) |

## Dev Agent Record

### Agent Model Used

### Debug Log References

### Completion Notes List

### File List

## QA Results

Gate: PASS â†’ docs/qa/gates/1.4-url-discovery-and-sitemap-parsing.yml
