# Story 3.3: Step 1 - Content Summarization Analysis

## Status
Approved

## Story
**As a** user,
**I want** LLM-powered content analysis for each page,
**so that** I understand the page's purpose, context, and role within the overall application workflow

## Acceptance Criteria
1. LLM analysis of page content to identify purpose, target users, and business context
2. Content hierarchy analysis including main sections, navigation patterns, and information architecture
3. User journey context identification showing entry points, exit paths, and workflow integration
4. Business logic overview extraction from page behavior and interactive elements
5. Structured output format capturing key insights in consistent, machine-readable format
6. Analysis confidence scoring to identify pages needing additional review
7. Processing time optimization targeting 60-90 seconds per page for Step 1 analysis

## Tasks / Subtasks
- [x] Construct Step 1 prompt templates ingesting page artifacts from Stories 2.2/2.5 (AC: 1-4)
- [x] Integrate summarization call into LLM engine using provider abstraction from Story 3.1 (AC: 1-4)
- [x] Parse LLM output into `ContentSummary` model with strict schema validation (AC: 5)
- [x] Derive navigation role and user journey metadata from summarized content (AC: 2,3)
- [x] Compute confidence scoring based on LLM metadata and heuristic checks (AC: 6)
- [x] Instrument execution timing and optimize batching/streaming to hit 60-90s target (AC: 7)

## Dev Notes
- Follow `docs/prd.md#story-33-step-1-content-summarization-analysis` for scope of insights to capture.
- Map parsed output to `ContentSummary` attributes defined in `docs/architecture.md#contentsummary`.
- Reuse page content, DOM, and interaction artifacts from `docs/stories/2.2.page-navigation-and-content-extraction.md` and `docs/stories/2.5.page-analysis-data-collection.md`.
- Apply LLM prompt design patterns from `docs/architecture.md#llm-integration-engine` to reduce hallucination risk.
- Log summarization metrics with structlog so progress tracking in `docs/prd.md#epic-4-progress-tracking--documentation-generation` can consume them.

### Testing

## Test Design

### Unit Tests (20 scenarios)

#### Prompt Template Tests
1. **test_step1_prompt_construction**
   - Given: Page artifacts from Stories 2.2/2.5 (content, DOM, interactions)
   - When: Step 1 prompt is constructed
   - Then: Prompt includes all required page context and analysis instructions

2. **test_prompt_template_validation**
   - Given: Various page content types and structures
   - When: Prompt templates are generated
   - Then: Templates are complete and properly formatted

3. **test_prompt_content_sanitization**
   - Given: Page content with potential injection risks
   - When: Content is included in prompts
   - Then: Content is properly sanitized and escaped

4. **test_prompt_size_optimization**
   - Given: Large page content exceeding token limits
   - When: Prompt is constructed
   - Then: Content is appropriately truncated while preserving key information

#### LLM Response Parsing Tests
5. **test_content_summary_schema_validation**
   - Given: Valid LLM response for content analysis
   - When: Response is parsed into ContentSummary model
   - Then: All required fields are populated with correct types

6. **test_malformed_llm_response_handling**
   - Given: Malformed JSON response from LLM
   - When: Response parsing is attempted
   - Then: ParseError is raised with recovery suggestions

7. **test_incomplete_analysis_response**
   - Given: LLM response missing required analysis fields
   - When: Response validation occurs
   - Then: Validation error identifies missing fields

8. **test_content_summary_serialization**
   - Given: Populated ContentSummary model
   - When: Model is serialized to JSON
   - Then: All fields are properly serialized and deserializable

#### Content Analysis Tests
9. **test_purpose_identification**
   - Given: Page content with clear business purpose
   - When: LLM analysis is performed
   - Then: Page purpose is accurately identified and categorized

10. **test_target_user_analysis**
    - Given: Page with specific user personas and use cases
    - When: Target user analysis is performed
    - Then: User types and contexts are correctly identified

11. **test_business_context_extraction**
    - Given: Page with business workflows and processes
    - When: Business context analysis is performed
    - Then: Business logic and context are accurately captured

12. **test_content_hierarchy_analysis**
    - Given: Page with complex navigation and information architecture
    - When: Hierarchy analysis is performed
    - Then: Main sections and navigation patterns are identified

#### Navigation and Journey Analysis Tests
13. **test_user_journey_context_identification**
    - Given: Page with entry points and exit paths
    - When: Journey context analysis is performed
    - Then: Entry/exit patterns and workflow integration are identified

14. **test_navigation_role_derivation**
    - Given: Page with specific navigation role in application
    - When: Navigation role is analyzed
    - Then: Role is correctly categorized (landing, workflow, detail, etc.)

15. **test_workflow_integration_analysis**
    - Given: Page connected to broader application workflows
    - When: Workflow integration is analyzed
    - Then: Connections and dependencies are identified

16. **test_information_architecture_mapping**
    - Given: Page with complex information structure
    - When: Architecture analysis is performed
    - Then: Information hierarchy and organization are captured

#### Confidence Scoring Tests
17. **test_confidence_scoring_calculation**
    - Given: Analysis results with varying completeness
    - When: Confidence scoring is computed
    - Then: Scores accurately reflect analysis quality and completeness

18. **test_low_confidence_detection**
    - Given: Page requiring additional manual review
    - When: Confidence scoring evaluates analysis
    - Then: Low confidence is flagged with specific reasons

19. **test_confidence_metadata_integration**
    - Given: LLM metadata and heuristic checks
    - When: Confidence scoring combines data sources
    - Then: Comprehensive confidence assessment is generated

20. **test_confidence_threshold_validation**
    - Given: Confidence scores across different page types
    - When: Threshold validation is performed
    - Then: Appropriate thresholds are applied per page category

### Integration Tests (15 scenarios)

#### LLM Engine Integration Tests
21. **test_llm_engine_integration_for_step1**
    - Given: Step 1 analysis request and configured LLM engine
    - When: Analysis is processed through engine
    - Then: Request is handled correctly with proper provider selection

22. **test_provider_fallback_during_step1_analysis**
    - Given: Primary LLM provider failure during analysis
    - When: Fallback mechanism activates
    - Then: Analysis completes using backup provider

23. **test_model_configuration_for_step1**
    - Given: STEP1_MODEL configuration from Story 3.2
    - When: Step 1 analysis is performed
    - Then: Correct model is used based on configuration

24. **test_concurrent_step1_analysis**
    - Given: Multiple simultaneous Step 1 analysis requests
    - When: Analyses are processed concurrently
    - Then: All analyses complete correctly without interference

#### Page Artifact Integration Tests
25. **test_integration_with_page_navigation_data**
    - Given: Page content from Story 2.2 navigation and extraction
    - When: Step 1 analysis processes the data
    - Then: All navigation artifacts are properly incorporated

26. **test_integration_with_interaction_data**
    - Given: Page interaction data from Story 2.4
    - When: Analysis incorporates interaction context
    - Then: Interactive elements inform purpose and journey analysis

27. **test_integration_with_network_data**
    - Given: Network traffic data from Story 2.3
    - When: Analysis includes network context
    - Then: API patterns inform business logic understanding

28. **test_screenshot_and_visual_context_integration**
    - Given: Page screenshots from Story 2.2
    - When: Visual context is analyzed
    - Then: Visual elements enhance content understanding

#### Analysis Pipeline Integration Tests
29. **test_step1_output_preparation_for_step2**
    - Given: Completed Step 1 analysis
    - When: Output is prepared for Step 2
    - Then: Context data is properly formatted for next stage

30. **test_step1_context_passing_validation**
    - Given: Step 1 results destined for Story 3.5 context passing
    - When: Context data is validated
    - Then: All required context fields are present and valid

31. **test_step1_metrics_and_logging_integration**
    - Given: Step 1 analysis execution
    - When: Metrics and logs are captured
    - Then: Structured logging supports progress tracking and diagnostics

32. **test_step1_error_handling_integration**
    - Given: Various failure scenarios during Step 1
    - When: Error handling activates
    - Then: Errors are properly categorized and recovery attempted

#### Performance and Timing Tests
33. **test_step1_execution_timing_optimization**
    - Given: Standard page analysis workload
    - When: Step 1 analysis is performed
    - Then: Execution completes within 60-90 second target window

34. **test_large_page_performance**
    - Given: Pages with extensive content and complex structure
    - When: Step 1 analysis is performed
    - Then: Performance remains within acceptable bounds

35. **test_batch_processing_performance**
    - Given: Multiple pages for batch Step 1 analysis
    - When: Batch processing is optimized
    - Then: Throughput targets are met with efficient resource usage

### E2E Tests (10 scenarios)

#### Complete Analysis Pipeline Tests
36. **test_end_to_end_step1_analysis**
    - Given: Complete page discovery and extraction pipeline
    - When: Step 1 analysis is performed on real pages
    - Then: Analysis completes successfully with quality results

37. **test_step1_in_full_discovery_workflow**
    - Given: Complete web discovery workflow from Epic 2
    - When: Step 1 analysis integrates with discovery pipeline
    - Then: Seamless integration produces comprehensive page insights

38. **test_multi_page_step1_analysis_session**
    - Given: Multiple pages requiring Step 1 analysis
    - When: Analysis session processes all pages
    - Then: Consistent quality and performance across all analyses

#### Real-World Page Type Tests
39. **test_step1_analysis_landing_pages**
    - Given: Various landing page types
    - When: Step 1 analysis is performed
    - Then: Landing page purposes and user journeys are correctly identified

40. **test_step1_analysis_application_pages**
    - Given: Complex application workflow pages
    - When: Step 1 analysis is performed
    - Then: Application context and business logic are accurately captured

41. **test_step1_analysis_content_pages**
    - Given: Content-heavy informational pages
    - When: Step 1 analysis is performed
    - Then: Content hierarchy and information architecture are identified

42. **test_step1_analysis_interactive_pages**
    - Given: Pages with forms, tools, and interactive elements
    - When: Step 1 analysis is performed
    - Then: Interactive purposes and user flows are captured

#### Quality and Reliability Tests
43. **test_step1_consistency_across_similar_pages**
    - Given: Similar pages with comparable content and structure
    - When: Step 1 analysis is performed on each
    - Then: Consistent analysis quality and categorization

44. **test_step1_confidence_scoring_accuracy**
    - Given: Pages requiring varying levels of manual review
    - When: Confidence scoring is applied
    - Then: Scores accurately predict need for human intervention

45. **test_step1_error_recovery_and_resilience**
    - Given: Various error conditions during analysis
    - When: Error recovery mechanisms activate
    - Then: Analysis completes or fails gracefully with useful information

### Test Data and Fixtures

#### Page Content Fixtures
- Landing pages with clear value propositions
- Application workflow pages with complex interactions
- Content-heavy pages with information hierarchies
- E-commerce pages with product catalogs and checkout flows
- Admin dashboards with data management interfaces

#### LLM Response Fixtures
- Valid ContentSummary responses for different page types
- Malformed responses for error handling testing
- Responses with varying confidence levels
- Edge cases for parsing validation

#### Performance Test Data
- Large pages with extensive content (>100KB HTML)
- Pages with complex DOM structures (>5000 elements)
- Pages with extensive interactive elements
- Batch processing datasets with mixed page types

### Performance Benchmarks
- Analysis completion time: 60-90 seconds per page (target)
- Confidence scoring accuracy: >85% correlation with manual review
- Schema validation success rate: >99% for well-formed responses
- Memory usage: <500MB per analysis for large pages

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-02-14 | 0.1 | Initial draft | John (PM) |

## Dev Agent Record

### Agent Model Used
Gemini

### Debug Log References
- `uv run pytest tests/unit/llm/`
- `uv run pytest tests/unit/mcp/`

### Completion Notes List
- Implemented `ContentSummarizer` to orchestrate Step 1 analysis.
- Created prompt templates in `llm/prompts/step1_summarize.py`.
- Added `summarize_page_content` tool to `mcp/analysis_tools.py`.
- Implemented confidence scoring based on response completeness.
- Added unit tests for prompt generation, the summarizer, and the new MCP tool.

### File List
- `src/legacy_web_mcp/llm/prompts/__init__.py`
- `src/legacy_web_mcp/llm/analysis/__init__.py`
- `src/legacy_web_mcp/llm/prompts/step1_summarize.py`
- `src/legacy_web_mcp/llm/analysis/step1_summarize.py`
- `src/legacy_web_mcp/mcp/analysis_tools.py`
- `tests/unit/llm/__init__.py`
- `tests/unit/llm/analysis/__init__.py`
- `tests/unit/llm/prompts/__init__.py`
- `tests/unit/llm/prompts/test_step1_summarize.py`
- `tests/unit/llm/analysis/test_step1_summarize.py`
- `tests/unit/mcp/test_analysis_tools.py`

## QA Results

Gate: PASS → docs/qa/gates/3.3-step-1-content-summarization-analysis.yml
